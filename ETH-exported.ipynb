{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from web3 import Web3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to read in YAML file\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "# Connect to Ethereum node\n",
    "rpc_url = 'https://eth.llamarpc.com'\n",
    "rpc_url = 'https://ethereum-rpc.publicnode.com'\n",
    "rpc_url = 'https://eth-mainnet.public.blastapi.io'\n",
    "rpc_url = 'https://mainnet.gateway.tenderly.co'\n",
    "w3 = Web3(Web3.HTTPProvider(rpc_url))\n",
    "\n",
    "# Function to get Ethereum balance for each address\n",
    "def get_eth_balance(w3: Web3, address, at_block='latest'):\n",
    "    try:\n",
    "        balance = w3.eth.get_balance(Web3.to_checksum_address(address), block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get ERC20 balance of a given coin & address\n",
    "def get_erc20_balance_ethereum(w3: Web3, coin, address, at_block='latest'):\n",
    "    contract_address = ethereum_token_addresses[coin]['contract']\n",
    "    ABI = ethereum_token_addresses[coin]['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(contract_address), abi=ABI)\n",
    "        balance = contract.functions.balanceOf(Web3.to_checksum_address(address)).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get prices of wstETH, we assume 1stETH = 1 ETH\n",
    "def get_ETH_wstETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['wstETH']['contract']\n",
    "    abi = ethereum_token_addresses['wstETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.stEthPerToken().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for wstETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of mETH\n",
    "def get_ETH_mETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['mETH']['staking_contract']\n",
    "    abi = ethereum_token_addresses['mETH']['staking_abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.mETHToETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for mETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of pufETH\n",
    "def get_ETH_pufETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['pufETH']['contract']\n",
    "    abi = ethereum_token_addresses['pufETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.convertToAssets(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for pufETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of weETH, assuming 1 eETH = 1 ETH\n",
    "def get_ETH_weETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['weETH']['contract']\n",
    "    abi = ethereum_token_addresses['weETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getEETHByWeETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for weETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of rETH\n",
    "def get_ETH_rETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['rETH']['contract']\n",
    "    abi = ethereum_token_addresses['rETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getExchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for rETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of cbETH\n",
    "def get_ETH_cbETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['cbETH']['contract']\n",
    "    abi = ethereum_token_addresses['cbETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.exchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for cbETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get the block number of the first block of the day using binary search\n",
    "def get_first_block_of_day(w3: Web3, target_date: datetime.date):\n",
    "    # Convert the target date to a UNIX timestamp (00:00:00 of that day in UTC)\n",
    "    start_of_day = datetime.datetime.combine(target_date, datetime.time(0, 0), tzinfo=datetime.timezone.utc)\n",
    "    start_timestamp = int(start_of_day.timestamp())\n",
    "\n",
    "    # Get the current block number (latest block)\n",
    "    latest_block = w3.eth.get_block('latest')['number']\n",
    "\n",
    "    # Perform binary search to find the block with the timestamp >= start_timestamp\n",
    "    low = 0\n",
    "    high = latest_block\n",
    "\n",
    "    while low < high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_block = w3.eth.get_block(mid)\n",
    "        if mid_block['timestamp'] < start_timestamp:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    # After the search, 'low' should be the first block of the day or a block at or after the target timestamp\n",
    "    first_block_of_day = w3.eth.get_block(low)\n",
    "\n",
    "    return first_block_of_day if first_block_of_day['timestamp'] >= start_timestamp else None\n",
    "\n",
    "# Function to lookup the block number of a given date using block_timestamps.csv\n",
    "def lookup_block_number(date: str):\n",
    "    df = pd.read_csv('block_timestamps.csv')\n",
    "    try:\n",
    "        block_number = int(df.loc[df['date'] == date, 'block'].values[0])\n",
    "    except:\n",
    "        block_number = None\n",
    "    return block_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill block_timestamps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last date in the csv\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "\n",
    "# get current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "while current_date > last_date:\n",
    "    # get block number\n",
    "    new_block = get_first_block_of_day(w3, last_date + datetime.timedelta(days=1))\n",
    "    new_row = pd.DataFrame({'date': [str(last_date + datetime.timedelta(days=1))], \n",
    "                            'block': [new_block['number']], \n",
    "                            'block_timestamp': [new_block['timestamp']]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    last_date = last_date + datetime.timedelta(days=1)\n",
    "    # save to csv\n",
    "    df.to_csv('block_timestamps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to create folder structure and empty csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an empty dataframe\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "df = df.drop(columns=['block', 'block_timestamp'])\n",
    "\n",
    "# create holdings folder\n",
    "if os.path.exists('holdings') == False:\n",
    "    os.mkdir('holdings')\n",
    "\n",
    "# create a dictionary for each entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    if os.path.exists(f\"holdings/{entity}\") == False:\n",
    "        os.mkdir(f\"holdings/{entity}\")\n",
    "\n",
    "# create subfolder for each chain in entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        if os.path.exists(f\"holdings/{entity}/{chain}\") == False:\n",
    "            os.mkdir(f\"holdings/{entity}/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            if os.path.exists(f\"holdings/{entity}/{chain}/{token}.csv\") == False:\n",
    "                df.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "# create prices folder\n",
    "if os.path.exists('prices') == False:\n",
    "    os.mkdir('prices')\n",
    "\n",
    "# create a folder for each chain in prices folder\n",
    "for chain in list(token_addresses.keys()):\n",
    "    if os.path.exists(f\"prices/{chain}\") == False:\n",
    "        os.mkdir(f\"prices/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for chain in list(token_addresses.keys()):\n",
    "    for token in list(token_addresses[chain]):\n",
    "        if os.path.exists(f\"prices/{chain}/{token}.csv\") == False:\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "\n",
    "### extend the csv files with the new dates\n",
    "\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            df = pd.read_csv(f\"holdings/{entity}/{chain}/{token}.csv\")\n",
    "            last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "            column_names = df.columns\n",
    "            for date in pd.date_range(start=last_date + datetime.timedelta(days=1), end=current_date):\n",
    "                new_row = pd.DataFrame({'date': [date.strftime('%Y-%m-%d')]}, columns=column_names)\n",
    "                new_row.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False, mode='a', header=False)\n",
    "\n",
    "for chain in list(token_addresses.keys()):\n",
    "    for token in list(token_addresses[chain]):\n",
    "        df = pd.read_csv(f\"prices/{chain}/{token}.csv\")\n",
    "        last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "        column_names = df.columns\n",
    "        for date in pd.date_range(start=last_date + datetime.timedelta(days=1), end=current_date):\n",
    "            new_row = pd.DataFrame({'date': [date.strftime('%Y-%m-%d')]}, columns=column_names)\n",
    "            new_row.to_csv(f\"prices/{chain}/{token}.csv\", index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill holdings on Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Beacon_chain_deposits\n",
      "Backfilling 0x00000000219ab540356cbb839cbe05303d7705fa\n",
      "Processing WETH\n",
      "Backfilling 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\n",
      "Processing Arbitrum\n",
      "Skipping 0x8315177ab297ba92a06054ce80a67ed4dbd7ed3a as already filled\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m         df[address] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m address \u001b[38;5;129;01min\u001b[39;00m addresses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# only process if the last row of the column is not yet filled\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as already filled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "for entity in track_bridged_eth.keys():\n",
    "\n",
    "    print(f\"Processing {entity}\")\n",
    "\n",
    "    for j in track_bridged_eth[entity]['ethereum']:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        asset = list(j.keys())[0]\n",
    "        addresses = j[asset]\n",
    "        df = pd.read_csv(f'holdings/{entity}/ethereum/{asset}.csv')\n",
    "        for address in addresses[0]['address']:\n",
    "            if address not in df.columns:\n",
    "                df[address] = None\n",
    "\n",
    "        for address in addresses[0]['address']:\n",
    "            # only process if the last row of the column is not yet filled\n",
    "            if np.isnan(df[address].iloc[-1]) == False:\n",
    "                print(f\"Skipping {address} as already filled\")\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Backfilling {address}\")\n",
    "                # iterate through each row from reverse until we get balance = 0\n",
    "                for i in range(len(df)-1, -1, -1):\n",
    "                    date = df['date'].iloc[i]\n",
    "                    block = lookup_block_number(date)\n",
    "                    #print(f\"Processing {date}\")\n",
    "                    if asset == 'ETH':\n",
    "                        balance = get_eth_balance(w3, address, block)\n",
    "                    else:\n",
    "                        balance = get_erc20_balance_ethereum(w3, asset, address, block)\n",
    "\n",
    "                    if df.loc[i, address] == None:\n",
    "                        df.loc[i, address] = balance\n",
    "                        df.to_csv(f\"holdings/{entity}/ethereum/{asset}.csv\", index=False)\n",
    "                    else: # stop if we already have a value (full backfilled)\n",
    "                        break\n",
    "\n",
    "                    # save to csv\n",
    "                    df.to_csv(f\"holdings/{entity}/ethereum/{asset}.csv\", index=False)\n",
    "\n",
    "                    # stop if balance is 0 = contract not yet used or deployed / no coins on it\n",
    "                    if balance == 0:\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if np.isnan(df[address].iloc[-1]):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[address].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ethereum\n",
      "Skipping wETH prices as already filled\n",
      "Skipping stETH prices as already filled\n",
      "Skipping wstETH prices as already filled\n",
      "Skipping mETH prices as already filled\n",
      "Skipping cbETH prices as already filled\n",
      "Skipping pufETH prices as already filled\n",
      "Skipping eETH prices as already filled\n",
      "Skipping weETH prices as already filled\n",
      "Backfilling rETH\n",
      "Error retrieving price for rETH: Could not decode contract function call to getExchangeRate with return data: b'', output_types: ['uint256']\n",
      "Error retrieving price for rETH: cannot access local variable 'price' where it is not associated with a value\n",
      "Assuming date reached where contract not yet deployed or implementation changed.\n"
     ]
    }
   ],
   "source": [
    "# only works for assets on ethereum L1 as of now!\n",
    "\n",
    "for chain in token_addresses:\n",
    "\n",
    "    print(f\"Processing {chain}\")\n",
    "\n",
    "    for token in token_addresses[chain]:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        df = pd.read_csv(f'prices/{chain}/{token}.csv')\n",
    "        if 'price' not in df.columns:\n",
    "            df['price'] = None\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "        # only process if the whole column is not yet filled\n",
    "        if df['price'].isnull().all() == False:\n",
    "            print(f\"Skipping {token} prices as already filled\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Backfilling {token}\")\n",
    "            # iterate through each row from reverse until we get price = 0\n",
    "            for i in range(len(df)-1, -1, -1):\n",
    "                date = df['date'].iloc[i]\n",
    "                block = lookup_block_number(date)\n",
    "                try:\n",
    "                    if token == 'wstETH':\n",
    "                        price = get_ETH_wstETH_price(w3, block)\n",
    "                    elif token == 'mETH':\n",
    "                        price = get_ETH_mETH_price(w3, block)\n",
    "                    elif token == 'pufETH':\n",
    "                        price = get_ETH_pufETH_price(w3, block)\n",
    "                    elif token == 'weETH':\n",
    "                        price = get_ETH_weETH_price(w3, block)\n",
    "                    elif token == 'rETH':\n",
    "                        price = get_ETH_rETH_price(w3, block)\n",
    "                    elif token == 'cbETH':\n",
    "                        price = get_ETH_cbETH_price(w3, block)\n",
    "                    elif token in ['wETH', 'stETH', 'eETH']: # assuming 1 token = 1 ETH\n",
    "                        price = 1\n",
    "                    else:\n",
    "                        print(f\"Token {token} not supported\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error retrieving price for {token}: {e}\")\n",
    "                    print(\"Assuming date reached where contract not yet deployed or implementation changed.\")\n",
    "                    break\n",
    "                df.loc[i, 'price'] = price\n",
    "\n",
    "                # save to csv\n",
    "                df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "                # stop if balance is 0 = contract not yet used\n",
    "                if price == 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to get the total supply over time ...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etherscan is paid plan only\n",
    "# Coingecko API is free but only estimate\n",
    "# DUNE???\n",
    "\n",
    "import requests\n",
    "\n",
    "# Etherscan API key\n",
    "ETHERSCAN_API_KEY = os.environ['ETHERSCAN_API_KEY']\n",
    "\n",
    "# Function to get ETH total supply at a block\n",
    "def get_eth_supply_at_block(block_number):\n",
    "    url = f'https://api.etherscan.io/api?module=proxy&action=eth_getBlockByNumber&tag={hex(block_number)}&boolean=true&apikey={ETHERSCAN_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'result' in data:\n",
    "        block_reward = int(data['result']['blockReward'], 16)  # Block reward in Wei\n",
    "        return block_reward / (10 ** 18)  # Convert Wei to ETH\n",
    "    else:\n",
    "        print(f\"Error fetching ETH supply at block {block_number}: {data}\")\n",
    "        return None\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
