{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from web3 import Web3\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to read in YAML file\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "# Connect to Ethereum node\n",
    "rpc_url = 'https://eth.llamarpc.com'\n",
    "rpc_url = 'https://ethereum-rpc.publicnode.com'\n",
    "rpc_url = 'https://eth-mainnet.public.blastapi.io'\n",
    "rpc_url = 'https://mainnet.gateway.tenderly.co'\n",
    "w3 = Web3(Web3.HTTPProvider(rpc_url))\n",
    "\n",
    "# Function to get Ethereum balance for each address\n",
    "def get_eth_balance(w3: Web3, address, at_block='latest'):\n",
    "    try:\n",
    "        balance = w3.eth.get_balance(Web3.to_checksum_address(address), block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get ERC20 balance of a given coin & address\n",
    "def get_erc20_balance_ethereum(w3: Web3, coin, address, at_block='latest'):\n",
    "    contract_address = ethereum_token_addresses[coin]['contract']\n",
    "    ABI = ethereum_token_addresses[coin]['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(contract_address), abi=ABI)\n",
    "        balance = contract.functions.balanceOf(Web3.to_checksum_address(address)).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get prices of wstETH, we assume 1stETH = 1 ETH\n",
    "def get_ETH_wstETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['wstETH']['contract']\n",
    "    abi = ethereum_token_addresses['wstETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.stEthPerToken().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for wstETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of mETH\n",
    "def get_ETH_mETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['mETH']['staking_contract']\n",
    "    abi = ethereum_token_addresses['mETH']['staking_abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.mETHToETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for mETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of pufETH\n",
    "def get_ETH_pufETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['pufETH']['contract']\n",
    "    abi = ethereum_token_addresses['pufETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.convertToAssets(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for pufETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of weETH, assuming 1 eETH = 1 ETH\n",
    "def get_ETH_weETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['weETH']['contract']\n",
    "    abi = ethereum_token_addresses['weETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getEETHByWeETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for weETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of rETH\n",
    "def get_ETH_rETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['rETH']['contract']\n",
    "    abi = ethereum_token_addresses['rETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getExchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for rETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of cbETH\n",
    "def get_ETH_cbETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['cbETH']['contract']\n",
    "    abi = ethereum_token_addresses['cbETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.exchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for cbETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get the block number of the first block of the day using binary search\n",
    "def get_first_block_of_day(w3: Web3, target_date: datetime.date):\n",
    "    # Convert the target date to a UNIX timestamp (00:00:00 of that day in UTC)\n",
    "    start_of_day = datetime.datetime.combine(target_date, datetime.time(0, 0), tzinfo=datetime.timezone.utc)\n",
    "    start_timestamp = int(start_of_day.timestamp())\n",
    "\n",
    "    # Get the current block number (latest block)\n",
    "    latest_block = w3.eth.get_block('latest')['number']\n",
    "\n",
    "    # Perform binary search to find the block with the timestamp >= start_timestamp\n",
    "    low = 0\n",
    "    high = latest_block\n",
    "\n",
    "    while low < high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_block = w3.eth.get_block(mid)\n",
    "        if mid_block['timestamp'] < start_timestamp:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    # After the search, 'low' should be the first block of the day or a block at or after the target timestamp\n",
    "    first_block_of_day = w3.eth.get_block(low)\n",
    "\n",
    "    return first_block_of_day if first_block_of_day['timestamp'] >= start_timestamp else None\n",
    "\n",
    "# Function to lookup the block number of a given date using block_timestamps.csv\n",
    "def lookup_block_number(date: str):\n",
    "    df = pd.read_csv('block_timestamps.csv')\n",
    "    try:\n",
    "        block_number = int(df.loc[df['date'] == date, 'block'].values[0])\n",
    "    except:\n",
    "        block_number = None\n",
    "    return block_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill block_timestamps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last date in the csv\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "\n",
    "# get current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "while current_date > last_date:\n",
    "    # get block number\n",
    "    new_block = get_first_block_of_day(w3, last_date + datetime.timedelta(days=1))\n",
    "    new_row = pd.DataFrame({'date': [str(last_date + datetime.timedelta(days=1))], \n",
    "                            'block': [new_block['number']], \n",
    "                            'block_timestamp': [new_block['timestamp']]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    last_date = last_date + datetime.timedelta(days=1)\n",
    "    # save to csv\n",
    "    df.to_csv('block_timestamps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to create folder structure and empty csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an empty dataframe\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "df = df.drop(columns=['block', 'block_timestamp'])\n",
    "\n",
    "# create holdings folder\n",
    "if os.path.exists('holdings') == False:\n",
    "    os.mkdir('holdings')\n",
    "\n",
    "# create a dictionary for each entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    if os.path.exists(f\"holdings/{entity}\") == False:\n",
    "        os.mkdir(f\"holdings/{entity}\")\n",
    "\n",
    "# create subfolder for each chain in entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        if os.path.exists(f\"holdings/{entity}/{chain}\") == False:\n",
    "            os.mkdir(f\"holdings/{entity}/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            if os.path.exists(f\"holdings/{entity}/{chain}/{token}.csv\") == False:\n",
    "                df.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "# create prices folder\n",
    "if os.path.exists('prices') == False:\n",
    "    os.mkdir('prices')\n",
    "\n",
    "# create a folder for each chain in prices folder\n",
    "for chain in list(token_addresses.keys()):\n",
    "    if os.path.exists(f\"prices/{chain}\") == False:\n",
    "        os.mkdir(f\"prices/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for chain in list(token_addresses.keys()):\n",
    "    for token in list(token_addresses[chain]):\n",
    "        if os.path.exists(f\"prices/{chain}/{token}.csv\") == False:\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "### extend the csv files with the new dates\n",
    "\n",
    "# append new dates to the csv files\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            df = pd.read_csv(f\"holdings/{entity}/{chain}/{token}.csv\")\n",
    "            for date in pd.date_range(start=last_date + datetime.timedelta(days=1), end=current_date):\n",
    "                new_row = pd.DataFrame({'date': [str(date)]})\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "            df.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill holdings on Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Beacon_chain_deposits\n",
      "Skipping 0x00000000219ab540356cbb839cbe05303d7705fa as already filled\n",
      "Processing WETH\n",
      "Skipping 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2 as already filled\n",
      "Processing Arbitrum\n",
      "Skipping 0x8315177ab297ba92a06054ce80a67ed4dbd7ed3a as already filled\n",
      "Skipping 0x011B6E24FfB0B5f5fCc564cf4183C5BBBc96D515 as already filled\n",
      "Skipping 0x0F25c1DC2a9922304f2eac71DCa9B07E310e8E5a as already filled\n",
      "Processing Base\n",
      "Skipping 0x49048044d57e1c92a77f79988d21fa8faf74e97e as already filled\n",
      "Skipping 0x9de443AdC5A411E83F1878Ef24C3F52C61571e72 as already filled\n",
      "Skipping 0x3154Cf16ccdb4C6d922629664174b904d80F2C35 as already filled\n",
      "Processing Optimism\n",
      "Skipping 0xbEb5Fc579115071764c7423A4f12eDde41f106Ed as already filled\n",
      "Skipping 0x76943C0D61395d8F2edF9060e1533529cAe05dE6 as already filled\n",
      "Processing Scroll\n",
      "Skipping 0x6774Bcbd5ceCeF1336b5300fb5186a12DDD8b367 as already filled\n",
      "Skipping 0xA033Ff09f2da45f0e9ae495f525363722Df42b2a as already filled\n",
      "Skipping 0x6625C6332c9F91F2D27c304E729B86db87A3f504 as already filled\n",
      "Processing Blast\n",
      "Skipping 0x98078db053902644191f93988341E31289E1C8FE as already filled\n",
      "Skipping 0x5F6AE08B8AeB7078cf2F96AFb089D7c9f51DA47d as already filled\n",
      "Skipping 0x98078db053902644191f93988341E31289E1C8FE as already filled\n",
      "Processing Mantle\n",
      "Skipping 0xc54cb22944F2bE476E02dECfCD7e3E7d3e15A8Fb as already filled\n",
      "Skipping 0x95fC37A27a2f68e3A647CDc081F0A89bb47c3012 as already filled\n",
      "Processing Zksync\n",
      "Skipping 0xD7f9f54194C633F36CCD5F3da84ad4a1c38cB2cB as already filled\n",
      "Skipping 0x41527B2d03844dB6b0945f25702cB958b6d55989 as already filled\n",
      "Processing Linea\n",
      "Skipping 0xd19d4B5d358258f05D7B411E21A1460D11B0876F as already filled\n",
      "Skipping 0x051F1D88f0aF5763fB888eC4378b4D8B29ea3319 as already filled\n",
      "Processing Starknet\n",
      "Skipping 0xae0Ee0A63A2cE6BaeEFFE56e7714FB4EFE48D419 as already filled\n",
      "Skipping 0xBf67F59D2988A46FBFF7ed79A621778a3Cd3985B as already filled\n",
      "Processing Manta_Pacific\n",
      "Skipping 0x9168765EE952de7C6f8fC6FaD5Ec209B960b7622 as already filled\n",
      "Processing Mode\n",
      "Skipping 0x8B34b14c7c7123459Cf3076b8Cb929BE097d0C07 as already filled\n",
      "Processing Metis\n",
      "Skipping 0x3980c9ed79d2c191A89E02Fa3529C60eD6e9c04b as already filled\n",
      "Processing Polygon_zkevm\n",
      "Skipping 0x2a3DD3EB832aF982ec71669E178424b10Dca2EDe as already filled\n",
      "Processing Polygon_POS\n",
      "Skipping 0x8484Ef722627bf18ca5Ae6BcF031c23E6e922B30 as already filled\n",
      "Processing Ronin\n",
      "Skipping 0x64192819Ac13Ef72bF6b5AE239AC672B43a9AF08 as already filled\n",
      "Processing Avalanche\n",
      "Skipping 0x8EB8a3b98659Cce290402893d0123abb75E3ab28 as already filled\n",
      "Skipping 0x8EB8a3b98659Cce290402893d0123abb75E3ab28 as already filled\n",
      "Processing PulseChain\n",
      "Skipping 0x1715a3E4A142d8b698131108995174F37aEBA10D as already filled\n",
      "Processing Aptos\n",
      "Skipping 0x50002CdFe7CCb0C41F519c6Eb0653158d11cd907 as already filled\n",
      "Processing Near\n",
      "Skipping 0x6BFaD42cFC4EfC96f529D786D643Ff4A8B89FA52 as already filled\n",
      "Processing Gnosis_Chain\n",
      "Skipping 0x88ad09518695c6c3712AC10a214bE5109a655671 as already filled\n",
      "Skipping 0x88ad09518695c6c3712AC10a214bE5109a655671 as already filled\n",
      "Skipping 0x88ad09518695c6c3712AC10a214bE5109a655671 as already filled\n",
      "Processing SUI\n",
      "Skipping 0x312e67b47A2A29AE200184949093D92369F80B53 as already filled\n",
      "Processing Worldchain\n",
      "Skipping 0xd5ec14a83B7d95BE1E2Ac12523e2dEE12Cbeea6C as already filled\n"
     ]
    }
   ],
   "source": [
    "for entity in track_bridged_eth.keys():\n",
    "\n",
    "    print(f\"Processing {entity}\")\n",
    "\n",
    "    for j in track_bridged_eth[entity]['ethereum']:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        asset = list(j.keys())[0]\n",
    "        addresses = j[asset]\n",
    "        df = pd.read_csv(f'holdings/{entity}/ethereum/{asset}.csv')\n",
    "        for address in addresses[0]['address']:\n",
    "            if address not in df.columns:\n",
    "                df[address] = None\n",
    "\n",
    "        for address in addresses[0]['address']:\n",
    "            # only process if the whole column is not yet filled\n",
    "            if df[address].isnull().all() == False:\n",
    "                print(f\"Skipping {address} as already filled\")\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Backfilling {address}\")\n",
    "                # iterate through each row from reverse until we get balance = 0\n",
    "                for i in range(len(df)-1, -1, -1):\n",
    "                    date = df['date'].iloc[i]\n",
    "                    block = lookup_block_number(date)\n",
    "                    #print(f\"Processing {date}\")\n",
    "                    if asset == 'ETH':\n",
    "                        balance = get_eth_balance(w3, address, block)\n",
    "                    else:\n",
    "                        balance = get_erc20_balance_ethereum(w3, asset, address, block)\n",
    "                    df.loc[i, address] = balance\n",
    "\n",
    "                    # save to csv\n",
    "                    df.to_csv(f\"holdings/{entity}/ethereum/{asset}.csv\", index=False)\n",
    "\n",
    "                    # stop if balance is 0 = contract not yet used or deployed / no coins on it\n",
    "                    if balance == 0:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ethereum\n",
      "Skipping wETH prices as already filled\n",
      "Skipping stETH prices as already filled\n",
      "Skipping wstETH prices as already filled\n",
      "Skipping mETH prices as already filled\n",
      "Skipping cbETH prices as already filled\n",
      "Skipping pufETH prices as already filled\n",
      "Skipping eETH prices as already filled\n",
      "Skipping weETH prices as already filled\n",
      "Backfilling rETH\n",
      "Error retrieving price for rETH: Could not decode contract function call to getExchangeRate with return data: b'', output_types: ['uint256']\n",
      "Error retrieving price for rETH: cannot access local variable 'price' where it is not associated with a value\n",
      "Assuming date reached where contract not yet deployed or implementation changed.\n"
     ]
    }
   ],
   "source": [
    "# only works for assets on ethereum L1 as of now!\n",
    "\n",
    "for chain in token_addresses:\n",
    "\n",
    "    print(f\"Processing {chain}\")\n",
    "\n",
    "    for token in token_addresses[chain]:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        df = pd.read_csv(f'prices/{chain}/{token}.csv')\n",
    "        if 'price' not in df.columns:\n",
    "            df['price'] = None\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "        # only process if the whole column is not yet filled\n",
    "        if df['price'].isnull().all() == False:\n",
    "            print(f\"Skipping {token} prices as already filled\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Backfilling {token}\")\n",
    "            # iterate through each row from reverse until we get price = 0\n",
    "            for i in range(len(df)-1, -1, -1):\n",
    "                date = df['date'].iloc[i]\n",
    "                block = lookup_block_number(date)\n",
    "                try:\n",
    "                    if token == 'wstETH':\n",
    "                        price = get_ETH_wstETH_price(w3, block)\n",
    "                    elif token == 'mETH':\n",
    "                        price = get_ETH_mETH_price(w3, block)\n",
    "                    elif token == 'pufETH':\n",
    "                        price = get_ETH_pufETH_price(w3, block)\n",
    "                    elif token == 'weETH':\n",
    "                        price = get_ETH_weETH_price(w3, block)\n",
    "                    elif token == 'rETH':\n",
    "                        price = get_ETH_rETH_price(w3, block)\n",
    "                    elif token == 'cbETH':\n",
    "                        price = get_ETH_cbETH_price(w3, block)\n",
    "                    elif token in ['wETH', 'stETH', 'eETH']: # assuming 1 token = 1 ETH\n",
    "                        price = 1\n",
    "                    else:\n",
    "                        print(f\"Token {token} not supported\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error retrieving price for {token}: {e}\")\n",
    "                    print(\"Assuming date reached where contract not yet deployed or implementation changed.\")\n",
    "                    break\n",
    "                df.loc[i, 'price'] = price\n",
    "\n",
    "                # save to csv\n",
    "                df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "                # stop if balance is 0 = contract not yet used\n",
    "                if price == 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to get the total supply over time ...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etherscan is paid plan only\n",
    "# Coingecko API is free but only estimate\n",
    "# DUNE???\n",
    "\n",
    "import requests\n",
    "\n",
    "# Etherscan API key\n",
    "ETHERSCAN_API_KEY = os.environ['ETHERSCAN_API_KEY']\n",
    "\n",
    "# Function to get ETH total supply at a block\n",
    "def get_eth_supply_at_block(block_number):\n",
    "    url = f'https://api.etherscan.io/api?module=proxy&action=eth_getBlockByNumber&tag={hex(block_number)}&boolean=true&apikey={ETHERSCAN_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'result' in data:\n",
    "        block_reward = int(data['result']['blockReward'], 16)  # Block reward in Wei\n",
    "        return block_reward / (10 ** 18)  # Convert Wei to ETH\n",
    "    else:\n",
    "        print(f\"Error fetching ETH supply at block {block_number}: {data}\")\n",
    "        return None\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
