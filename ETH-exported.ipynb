{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from web3 import Web3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to read in YAML file\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "# Connect to Ethereum node\n",
    "rpc_url = 'https://eth.llamarpc.com'\n",
    "rpc_url = 'https://ethereum-rpc.publicnode.com'\n",
    "rpc_url = 'https://eth-mainnet.public.blastapi.io'\n",
    "rpc_url = 'https://mainnet.gateway.tenderly.co'\n",
    "w3 = Web3(Web3.HTTPProvider(rpc_url))\n",
    "\n",
    "# Function to get Ethereum balance for each address\n",
    "def get_eth_balance(w3: Web3, address, at_block='latest'):\n",
    "    try:\n",
    "        balance = w3.eth.get_balance(Web3.to_checksum_address(address), block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get ERC20 balance of a given coin & address\n",
    "def get_erc20_balance_ethereum(w3: Web3, coin, address, at_block='latest'):\n",
    "    contract_address = ethereum_token_addresses[coin]['contract']\n",
    "    ABI = ethereum_token_addresses[coin]['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(contract_address), abi=ABI)\n",
    "        balance = contract.functions.balanceOf(Web3.to_checksum_address(address)).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving balance for {address}: {e}\")\n",
    "    return balance\n",
    "\n",
    "# Function to get prices of wstETH, we assume 1stETH = 1 ETH\n",
    "def get_ETH_wstETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['wstETH']['contract']\n",
    "    abi = ethereum_token_addresses['wstETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.stEthPerToken().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for wstETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of mETH\n",
    "def get_ETH_mETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['mETH']['staking_contract']\n",
    "    abi = ethereum_token_addresses['mETH']['staking_abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.mETHToETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for mETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of pufETH\n",
    "def get_ETH_pufETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['pufETH']['contract']\n",
    "    abi = ethereum_token_addresses['pufETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.convertToAssets(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for pufETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of weETH, assuming 1 eETH = 1 ETH\n",
    "def get_ETH_weETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['weETH']['contract']\n",
    "    abi = ethereum_token_addresses['weETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getEETHByWeETH(10**18).call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for weETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of rETH\n",
    "def get_ETH_rETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['rETH']['contract']\n",
    "    abi = ethereum_token_addresses['rETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.getExchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for rETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of cbETH\n",
    "def get_ETH_cbETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['cbETH']['contract']\n",
    "    abi = ethereum_token_addresses['cbETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.exchangeRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for cbETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of sfrxETH\n",
    "def get_ETH_sfrxETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['sfrxETH']['contract']\n",
    "    abi = ethereum_token_addresses['sfrxETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.pricePerShare().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for sfrxETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of rswETH \n",
    "def get_ETH_rswETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['rswETH']['contract']\n",
    "    abi = ethereum_token_addresses['rswETH']['abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = contract.functions.rswETHToETHRate().call(block_identifier=at_block) / 10**18\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for rswETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of rsETH \n",
    "def get_ETH_rsETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['rsETH']['deposit_contract']\n",
    "    abi = ethereum_token_addresses['rsETH']['deposit_abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        price = 10**18/contract.functions.getRsETHAmountToMint(ethereum_token_addresses['stETH']['contract'], 10**18).call(block_identifier=at_block)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for rsETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get price of ezETH \n",
    "def get_ETH_ezETH_price(w3: Web3, at_block='latest'):\n",
    "    address = ethereum_token_addresses['ezETH']['contract']\n",
    "    abi = ethereum_token_addresses['ezETH']['abi']\n",
    "    deposit_address = ethereum_token_addresses['ezETH']['deposit_contract']\n",
    "    deposit_abi = ethereum_token_addresses['ezETH']['deposit_abi']\n",
    "    try:\n",
    "        contract = w3.eth.contract(address=Web3.to_checksum_address(address), abi=abi)\n",
    "        deposit_contract = w3.eth.contract(address=Web3.to_checksum_address(deposit_address), abi=deposit_abi)\n",
    "        total_supply_ezETH = contract.functions.totalSupply().call(block_identifier=at_block)\n",
    "        total_eth = deposit_contract.functions.calculateTVLs().call(block_identifier=at_block)[2]\n",
    "        price = total_eth / total_supply_ezETH\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for ezETH: {e}\")\n",
    "    return price\n",
    "\n",
    "# Function to get the block number of the first block of the day using binary search\n",
    "def get_first_block_of_day(w3: Web3, target_date: datetime.date):\n",
    "    # Convert the target date to a UNIX timestamp (00:00:00 of that day in UTC)\n",
    "    start_of_day = datetime.datetime.combine(target_date, datetime.time(0, 0), tzinfo=datetime.timezone.utc)\n",
    "    start_timestamp = int(start_of_day.timestamp())\n",
    "\n",
    "    # Get the current block number (latest block)\n",
    "    latest_block = w3.eth.get_block('latest')['number']\n",
    "\n",
    "    # Perform binary search to find the block with the timestamp >= start_timestamp\n",
    "    low = 0\n",
    "    high = latest_block\n",
    "\n",
    "    while low < high:\n",
    "        mid = (low + high) // 2\n",
    "        mid_block = w3.eth.get_block(mid)\n",
    "        if mid_block['timestamp'] < start_timestamp:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    # After the search, 'low' should be the first block of the day or a block at or after the target timestamp\n",
    "    first_block_of_day = w3.eth.get_block(low)\n",
    "\n",
    "    return first_block_of_day if first_block_of_day['timestamp'] >= start_timestamp else None\n",
    "\n",
    "# Function to lookup the block number of a given date using block_timestamps.csv\n",
    "def lookup_block_number(date: str):\n",
    "    df = pd.read_csv('block_timestamps.csv')\n",
    "    try:\n",
    "        block_number = int(df.loc[df['date'] == date, 'block'].values[0])\n",
    "    except:\n",
    "        block_number = None\n",
    "    return block_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill block_timestamps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last date in the csv\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "\n",
    "# get current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "while current_date > last_date:\n",
    "    # get block number\n",
    "    new_block = get_first_block_of_day(w3, last_date + datetime.timedelta(days=1))\n",
    "    new_row = pd.DataFrame({'date': [str(last_date + datetime.timedelta(days=1))], \n",
    "                            'block': [new_block['number']], \n",
    "                            'block_timestamp': [new_block['timestamp']]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    last_date = last_date + datetime.timedelta(days=1)\n",
    "    # save to csv\n",
    "    df.to_csv('block_timestamps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to create folder structure and empty csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an empty dataframe\n",
    "df = pd.read_csv('block_timestamps.csv')\n",
    "df = df.drop(columns=['block', 'block_timestamp'])\n",
    "\n",
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "# create holdings folder\n",
    "if os.path.exists('holdings') == False:\n",
    "    os.mkdir('holdings')\n",
    "\n",
    "# create a dictionary for each entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    if os.path.exists(f\"holdings/{entity}\") == False:\n",
    "        os.mkdir(f\"holdings/{entity}\")\n",
    "\n",
    "# create subfolder for each chain in entity\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        if os.path.exists(f\"holdings/{entity}/{chain}\") == False:\n",
    "            os.mkdir(f\"holdings/{entity}/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            if os.path.exists(f\"holdings/{entity}/{chain}/{token}.csv\") == False:\n",
    "                df.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "# create prices folder\n",
    "if os.path.exists('prices') == False:\n",
    "    os.mkdir('prices')\n",
    "\n",
    "# create a folder for each chain in prices folder\n",
    "for chain in list(token_addresses.keys()):\n",
    "    if os.path.exists(f\"prices/{chain}\") == False:\n",
    "        os.mkdir(f\"prices/{chain}\")\n",
    "\n",
    "# create a csv file for each token in each chain\n",
    "for chain in list(token_addresses.keys()):\n",
    "    for token in list(token_addresses[chain]):\n",
    "        if os.path.exists(f\"prices/{chain}/{token}.csv\") == False:\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "\n",
    "### extend the csv files with the new dates\n",
    "\n",
    "for entity in list(track_bridged_eth):\n",
    "    for chain in list(track_bridged_eth[entity]):\n",
    "        for token in [list(item.keys())[0] for item in track_bridged_eth[entity][chain]]:\n",
    "            df = pd.read_csv(f\"holdings/{entity}/{chain}/{token}.csv\")\n",
    "            last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "            column_names = df.columns\n",
    "            for date in pd.date_range(start=last_date + datetime.timedelta(days=1), end=current_date):\n",
    "                new_row = pd.DataFrame({'date': [date.strftime('%Y-%m-%d')]}, columns=column_names)\n",
    "                new_row.to_csv(f\"holdings/{entity}/{chain}/{token}.csv\", index=False, mode='a', header=False)\n",
    "\n",
    "for chain in list(token_addresses.keys()):\n",
    "    for token in list(token_addresses[chain]):\n",
    "        df = pd.read_csv(f\"prices/{chain}/{token}.csv\")\n",
    "        last_date = pd.to_datetime(df['date'].iloc[-1]).date()\n",
    "        column_names = df.columns\n",
    "        for date in pd.date_range(start=last_date + datetime.timedelta(days=1), end=current_date):\n",
    "            new_row = pd.DataFrame({'date': [date.strftime('%Y-%m-%d')]}, columns=column_names)\n",
    "            new_row.to_csv(f\"prices/{chain}/{token}.csv\", index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill holdings on Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Beacon_chain_deposits\n",
      "Backfilling 0x00000000219ab540356cbb839cbe05303d7705fa\n",
      "Processing Arbitrum\n",
      "Backfilling 0x8315177ab297ba92a06054ce80a67ed4dbd7ed3a\n",
      "Backfilling 0x011B6E24FfB0B5f5fCc564cf4183C5BBBc96D515\n",
      "Backfilling 0x0F25c1DC2a9922304f2eac71DCa9B07E310e8E5a\n",
      "Processing Base\n",
      "Backfilling 0x49048044d57e1c92a77f79988d21fa8faf74e97e\n",
      "Backfilling 0x9de443AdC5A411E83F1878Ef24C3F52C61571e72\n",
      "Backfilling 0x3154Cf16ccdb4C6d922629664174b904d80F2C35\n",
      "Processing Optimism\n",
      "Backfilling 0xbEb5Fc579115071764c7423A4f12eDde41f106Ed\n",
      "Backfilling 0x99C9fc46f92E8a1c0deC1b1747d010903E884bE1\n",
      "Backfilling 0x76943C0D61395d8F2edF9060e1533529cAe05dE6\n",
      "Processing Scroll\n",
      "Backfilling 0x6774Bcbd5ceCeF1336b5300fb5186a12DDD8b367\n",
      "Backfilling 0xA033Ff09f2da45f0e9ae495f525363722Df42b2a\n",
      "Backfilling 0x6625C6332c9F91F2D27c304E729B86db87A3f504\n",
      "Processing Blast\n",
      "Backfilling 0x98078db053902644191f93988341E31289E1C8FE\n",
      "Backfilling 0x5F6AE08B8AeB7078cf2F96AFb089D7c9f51DA47d\n",
      "Backfilling 0x98078db053902644191f93988341E31289E1C8FE\n",
      "Processing Mantle\n",
      "Backfilling 0xc54cb22944F2bE476E02dECfCD7e3E7d3e15A8Fb\n",
      "Backfilling 0x95fC37A27a2f68e3A647CDc081F0A89bb47c3012\n",
      "Backfilling 0x95fC37A27a2f68e3A647CDc081F0A89bb47c3012\n",
      "Processing Zksync\n",
      "Backfilling 0xD7f9f54194C633F36CCD5F3da84ad4a1c38cB2cB\n",
      "Backfilling 0x32400084C286CF3E17e7B677ea9583e60a000324\n",
      "Backfilling 0x41527B2d03844dB6b0945f25702cB958b6d55989\n",
      "Processing Linea\n",
      "Backfilling 0xd19d4B5d358258f05D7B411E21A1460D11B0876F\n",
      "Backfilling 0x051F1D88f0aF5763fB888eC4378b4D8B29ea3319\n",
      "Processing Starknet\n",
      "Backfilling 0xae0Ee0A63A2cE6BaeEFFE56e7714FB4EFE48D419\n",
      "Backfilling 0xBf67F59D2988A46FBFF7ed79A621778a3Cd3985B\n",
      "Processing Manta_Pacific\n",
      "Backfilling 0x9168765EE952de7C6f8fC6FaD5Ec209B960b7622\n",
      "Processing Mode\n",
      "Backfilling 0x8B34b14c7c7123459Cf3076b8Cb929BE097d0C07\n",
      "Processing Metis\n",
      "Backfilling 0x3980c9ed79d2c191A89E02Fa3529C60eD6e9c04b\n",
      "Processing Polygon_zkevm\n",
      "Backfilling 0x2a3DD3EB832aF982ec71669E178424b10Dca2EDe\n",
      "Processing Polygon_POS\n",
      "Backfilling 0x8484Ef722627bf18ca5Ae6BcF031c23E6e922B30\n",
      "Backfilling 0xa45b966996374E9e65ab991C6FE4Bfce3a56DDe8\n",
      "Processing Ronin\n",
      "Backfilling 0x64192819Ac13Ef72bF6b5AE239AC672B43a9AF08\n",
      "Backfilling 0x1A2a1c938CE3eC39b6D47113c7955bAa9DD454F2\n",
      "Backfilling 0x64192819Ac13Ef72bF6b5AE239AC672B43a9AF08\n",
      "Backfilling 0x1A2a1c938CE3eC39b6D47113c7955bAa9DD454F2\n",
      "Processing Avalanche\n",
      "Backfilling 0x8EB8a3b98659Cce290402893d0123abb75E3ab28\n",
      "Backfilling 0xE78388b4CE79068e89Bf8aA7f218eF6b9AB0e9d0\n",
      "Backfilling 0x8EB8a3b98659Cce290402893d0123abb75E3ab28\n",
      "Backfilling 0xE78388b4CE79068e89Bf8aA7f218eF6b9AB0e9d0\n",
      "Processing PulseChain\n",
      "Backfilling 0x1715a3E4A142d8b698131108995174F37aEBA10D\n",
      "Processing Aptos\n",
      "Backfilling 0x50002CdFe7CCb0C41F519c6Eb0653158d11cd907\n",
      "Processing Near\n",
      "Backfilling 0x6BFaD42cFC4EfC96f529D786D643Ff4A8B89FA52\n",
      "Backfilling 0x23Ddd3e3692d1861Ed57EDE224608875809e127f\n",
      "Processing Gnosis_Chain\n",
      "Backfilling 0x88ad09518695c6c3712AC10a214bE5109a655671\n",
      "Backfilling 0x88ad09518695c6c3712AC10a214bE5109a655671\n",
      "Backfilling 0x88ad09518695c6c3712AC10a214bE5109a655671\n",
      "Processing SUI\n",
      "Backfilling 0x312e67b47A2A29AE200184949093D92369F80B53\n",
      "Processing Worldchain\n",
      "Backfilling 0xd5ec14a83B7d95BE1E2Ac12523e2dEE12Cbeea6C\n",
      "Processing Sollet\n",
      "Backfilling 0xeae57ce9cc1984F202e15e038B964bb8bdF7229a\n",
      "Processing Wormhole\n",
      "Backfilling 0x3ee18B2214AFF97000D974cf647E7C347E8fa585\n",
      "Backfilling 0xf92cD566Ea4864356C5491c177A430C222d7e678\n",
      "Processing Stargate\n",
      "Backfilling 0x72E2F4830b9E45d52F80aC08CB2bEC0FeF72eD9c\n",
      "Backfilling 0x77b2043768d28E9C9aB44E1aBfC95944bcE57931\n",
      "Backfilling 0xA572d137666DCbAdFA47C3fC41F15e90134C618c\n",
      "Backfilling 0x268Ca24DAefF1FaC2ed883c598200CcbB79E931D\n",
      "Processing Orbiter\n",
      "Backfilling 0x80C67432656d59144cEFf962E8fAF8926599bCF8\n",
      "Processing Orbit\n",
      "Backfilling 0x1Bf68A9d1EaEe7826b3593C20a0ca93293cb489a\n",
      "Processing Across\n",
      "Backfilling 0xc186fA914353c44b2E33eBE05f21846F1048bEda\n",
      "Backfilling 0xc186fA914353c44b2E33eBE05f21846F1048bEda\n",
      "Backfilling 0x5c7BCd6E7De5423a257D81B442095A1a6ced35C5\n",
      "Backfilling 0x4D9079Bb4165aeb4084c526a32695dCfd2F77381\n",
      "Processing RhinoFi\n",
      "Backfilling 0x5d22045DAcEAB03B158031eCB7D9d06Fad24609b\n",
      "Processing Connext\n",
      "Backfilling 0x8898B472C54c31894e3B9bb83cEA802a5d0e63C6\n",
      "Backfilling 0xd44E91CfBBAa7b3B259A12a43b38CEBf47B463D5\n",
      "Backfilling 0xC8140dA31E6bCa19b287cC35531c2212763C2059\n",
      "Processing Hop\n",
      "Backfilling 0xb8901acB165ed027E32754E0FFe830802919727f\n",
      "Processing Fraxferry\n",
      "Backfilling 0x505603e2440b44C1602b44D0Eb8385399b3F7bab\n",
      "Backfilling 0x8afd5082E0C24dEcEA39A9eFb14e4ACF4373D7D6\n",
      "Processing Harmony\n",
      "Backfilling 0xF9Fb1c508Ff49F78b60d3A96dea99Fa5d7F3A8A6\n",
      "Processing LayerZero\n",
      "Backfilling 0xFE7fe01F8B9A76803aF3750144C2715D9bcf7D0D\n",
      "Backfilling 0x1f55a02A049033E3419a8E2975cF3F572F4e6E9A\n",
      "Backfilling 0x1cd5b73d12CB23b2835C873E4FaFfE83bBCef208\n",
      "Backfilling 0x85d456B2DfF1fd8245387C0BfB64Dfb700e98Ef3\n",
      "Processing Nomad\n",
      "Backfilling 0x88A69B4E698A4B090DF6CF5Bd7B2D47325Ad30A3\n",
      "Processing Optics\n",
      "Backfilling 0x6a39909e805A3eaDd2b61fFf61147796ca6aBB47\n",
      "Backfilling 0x4fc16De11deAc71E8b2Db539d82d93BE4b486892\n",
      "Processing Axler\n",
      "Backfilling 0x4F4495243837681061C4743b74B3eEdf548D56A5\n",
      "Processing Derive\n",
      "Backfilling 0x4BB4C3CDc7562f08e9910A0C7D8bB7e108861eB4\n",
      "Backfilling 0x8180EcCC825b692ef65FF099a0A387743788bf78\n",
      "Backfilling 0xD4efe33C66B8CdE33B8896a2126E41e5dB571b7e\n",
      "Backfilling 0xeBB5D642aA8ccDeE98373D6aC3ee0602b63824b3\n",
      "Backfilling 0x35d4D9bc79B0a543934b1769304B90d752691caD\n",
      "Processing Kinto\n",
      "Backfilling 0xc5d01939Af7Ce9Ffc505F0bb36eFeDde7920f2dc\n",
      "Backfilling 0x0f1b7bd7762662B23486320AA91F30312184f70C\n",
      "Backfilling 0xeB66259d2eBC3ed1d3a98148f6298927d8A36397\n",
      "Backfilling 0x0f1b7bd7762662B23486320AA91F30312184f70C\n",
      "Backfilling 0x00A0c9d82B95a17Cdf2D46703F2DcA13EB0E8A94\n",
      "Backfilling 0x0f1b7bd7762662B23486320AA91F30312184f70C\n",
      "Processing Synapse\n",
      "Backfilling 0x2796317b0fF8538F253012862c06787Adfb8cEb6\n",
      "Backfilling 0x2796317b0fF8538F253012862c06787Adfb8cEb6\n"
     ]
    }
   ],
   "source": [
    "# read in all yaml files\n",
    "token_addresses = read_yaml_file('token-addresses.yml')\n",
    "ethereum_token_addresses = token_addresses['ethereum']\n",
    "track_bridged_eth = read_yaml_file('track-bridged-eth.yml')\n",
    "\n",
    "for entity in track_bridged_eth.keys():\n",
    "\n",
    "    print(f\"Processing {entity}\")\n",
    "\n",
    "    for j in track_bridged_eth[entity]['ethereum']:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        asset = list(j.keys())[0]\n",
    "        addresses = j[asset]\n",
    "        df = pd.read_csv(f'holdings/{entity}/ethereum/{asset}.csv')\n",
    "        for address in addresses[0]['address']:\n",
    "            if address not in df.columns:\n",
    "                df[address] = np.nan\n",
    "\n",
    "        for address in addresses[0]['address']:\n",
    "            # only process if the last row of the column is not yet filled\n",
    "            if np.isnan(df[address].iloc[-1]) == False:\n",
    "                print(f\"Skipping {address} as already filled\")\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"Backfilling {address}\")\n",
    "                # iterate through each row from reverse until we get balance = 0\n",
    "                for i in range(len(df)-1, -1, -1):\n",
    "                    date = df['date'].iloc[i]\n",
    "                    block = lookup_block_number(date)\n",
    "                    #print(f\"Processing {date}\")\n",
    "                    if asset == 'ETH':\n",
    "                        balance = get_eth_balance(w3, address, block)\n",
    "                    else:\n",
    "                        balance = get_erc20_balance_ethereum(w3, asset, address, block)\n",
    "\n",
    "                    if np.isnan(df.loc[i, address]):\n",
    "                        df.loc[i, address] = balance\n",
    "                        if i % 100 == 0:\n",
    "                            df.to_csv(f\"holdings/{entity}/ethereum/{asset}.csv\", index=False)\n",
    "                    else: # stop if we already have a value (full backfilled)\n",
    "                        break\n",
    "\n",
    "                    # stop also if balance is 0 = contract not yet used or deployed / no coins on it\n",
    "                    #if balance == 0:\n",
    "                    #    break\n",
    "\n",
    "                # save to csv\n",
    "                df.to_csv(f\"holdings/{entity}/ethereum/{asset}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to backfill prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ethereum\n",
      "Backfilling wETH\n",
      "Backfilling stETH\n",
      "Backfilling wstETH\n",
      "Backfilling mETH\n",
      "Backfilling cbETH\n",
      "Backfilling pufETH\n",
      "Backfilling eETH\n",
      "Backfilling weETH\n",
      "Backfilling rETH\n",
      "Backfilling ezETH\n",
      "Backfilling frxETH\n",
      "Backfilling sfrxETH\n",
      "Backfilling pxETH\n",
      "Backfilling rswETH\n",
      "Backfilling rsETH\n"
     ]
    }
   ],
   "source": [
    "# only works for assets on ethereum L1 as of now!\n",
    "\n",
    "for chain in token_addresses:\n",
    "\n",
    "    print(f\"Processing {chain}\")\n",
    "\n",
    "    for token in token_addresses[chain]:\n",
    "\n",
    "        # create a column for each address if not already in the dataframe\n",
    "        df = pd.read_csv(f'prices/{chain}/{token}.csv')\n",
    "        if 'price' not in df.columns:\n",
    "            df['price'] = None\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)\n",
    "\n",
    "        # only process if the whole column is not yet filled\n",
    "        if np.isnan(df['price'].iloc[-1]) == False:\n",
    "            print(f\"Skipping {token} as already filled\")\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Backfilling {token}\")\n",
    "            # iterate through each row from reverse until we get price = 0\n",
    "            for i in range(len(df)-1, -1, -1):\n",
    "                date = df['date'].iloc[i]\n",
    "                block = lookup_block_number(date)\n",
    "                try:\n",
    "                    if token == 'wstETH':\n",
    "                        price = get_ETH_wstETH_price(w3, block)\n",
    "                    elif token == 'mETH':\n",
    "                        price = get_ETH_mETH_price(w3, block)\n",
    "                    elif token == 'pufETH':\n",
    "                        price = get_ETH_pufETH_price(w3, block)\n",
    "                    elif token == 'weETH':\n",
    "                        price = get_ETH_weETH_price(w3, block)\n",
    "                    elif token == 'rETH':\n",
    "                        price = get_ETH_rETH_price(w3, block)\n",
    "                    elif token == 'cbETH':\n",
    "                        price = get_ETH_cbETH_price(w3, block)\n",
    "                    elif token == 'sfrxETH':\n",
    "                        price = get_ETH_sfrxETH_price(w3, block)\n",
    "                    elif token == 'rswETH':\n",
    "                        price = get_ETH_rswETH_price(w3, block)\n",
    "                    elif token == 'rsETH':\n",
    "                        price = get_ETH_rsETH_price(w3, block)\n",
    "                    elif token == 'ezETH':\n",
    "                        price = get_ETH_ezETH_price(w3, block)\n",
    "                    elif token in ['wETH', 'stETH', 'eETH', 'pxETH', 'frxETH']: # assuming 1 token = 1 ETH\n",
    "                        price = 1\n",
    "                    else:\n",
    "                        print(f\"Token {token} not supported\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error retrieving price for {token}: {e}\")\n",
    "                    print(\"Assuming date reached where contract not yet deployed or implementation changed.\")\n",
    "                    break\n",
    "                df.loc[i, 'price'] = price\n",
    "\n",
    "                # break the loop if value is filled\n",
    "                if np.isnan(df.loc[i-1, 'price']) == False:\n",
    "                    break\n",
    "\n",
    "                # stop if balance is 0 = contract not yet used\n",
    "                if price == 0:\n",
    "                    break\n",
    "\n",
    "            # save to csv\n",
    "            df.to_csv(f\"prices/{chain}/{token}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for Bitcoin RPC endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total BTC supply: 19774193.75\n"
     ]
    }
   ],
   "source": [
    "# this script get the current block number and then calculates the total supply of BTC based on the issuance schedule\n",
    "import requests\n",
    "import json\n",
    "\n",
    "btc_rpc = 'https://rpc.ankr.com/btc'\n",
    "\n",
    "def bitcoin_rpc_call(method, params=[]):\n",
    "    headers = {'content-type': 'application/json'}\n",
    "\n",
    "    # No authentication required for public rpcs\n",
    "    payload = json.dumps({\n",
    "        \"method\": method,\n",
    "        \"params\": params,\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 0,\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        response = requests.post(btc_rpc, headers=headers, data=payload)\n",
    "        response.raise_for_status()  # Check for HTTP request errors\n",
    "        return response.json().get('result')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "def calculate_btc_supply(block_height):\n",
    "    total_supply = 0 # at block 0\n",
    "    reward = 50  # Initial block reward\n",
    "    halving_interval = 210000\n",
    "\n",
    "    # Loop over halving periods\n",
    "    i = 0\n",
    "    while block_height > 0:\n",
    "        blocks_in_current_period = min(block_height, halving_interval)\n",
    "        total_supply += blocks_in_current_period * reward\n",
    "        block_height -= blocks_in_current_period\n",
    "        reward /= 2  # Halve the reward\n",
    "        i += 1\n",
    "\n",
    "    return total_supply\n",
    "\n",
    "# full list of rpc endpoints for bitcoin: https://developer.bitcoin.org/reference/rpc/\n",
    "latest_block_count = bitcoin_rpc_call(\"getblockcount\")\n",
    "total_btc = calculate_btc_supply(latest_block_count)\n",
    "print(f\"Total BTC supply: {total_btc}\")\n",
    "\n",
    "# TODO: write a script that gets the first bitcoin block for each day\n",
    "# TODO: then backfill the supply of BTC at each block using calculate_btc_supply (offline compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Total Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we base this on historic yearly data (above ground stock) & linear interpolate number between know data points\n",
    "# in case the date is in the future we project the growth rate of the last year into the future linearly \n",
    "# source which is updatede yearly: https://www.gold.org/goldhub/data/how-much-gold#from-login=1&just-verified=1\n",
    "\n",
    "data = {\n",
    "    \"2010\": 168245.7,\n",
    "    \"2011\": 171145.0,\n",
    "    \"2012\": 174056.9,\n",
    "    \"2013\": 177195.8,\n",
    "    \"2014\": 180571.2,\n",
    "    \"2015\": 183945.4,\n",
    "    \"2016\": 187498.2,\n",
    "    \"2017\": 191048.4,\n",
    "    \"2018\": 194692.7,\n",
    "    \"2019\": 198295.2,\n",
    "    \"2020\": 201738.2,\n",
    "    \"2021\": 205309.3,\n",
    "    \"2022\": 208921.0,\n",
    "    \"2023\": 212582.5\n",
    "}\n",
    "\n",
    "def get_gold_above_ground_supply(date: datetime, data: dict):\n",
    "\n",
    "    # Convert years to ints for easier comparison\n",
    "    data_years = {int(k): v for k, v in data.items()}\n",
    "    year = date.year\n",
    "    \n",
    "    # Calculate day progress (0 to 1)\n",
    "    days_in_year = 366 if year % 4 == 0 else 365\n",
    "    progress = (date.timetuple().tm_yday - 1) / days_in_year\n",
    "    \n",
    "    # Handle dates within data range\n",
    "    if year in data_years:\n",
    "        if progress == 1.0:\n",
    "            return data_years[year]\n",
    "            \n",
    "        next_year = year + 1\n",
    "        if next_year in data_years:\n",
    "            # Simple linear interpolation between years\n",
    "            return round(data_years[year] + (data_years[next_year] - data_years[year]) * progress, 1)\n",
    "    \n",
    "    # Handle future dates\n",
    "    max_year = max(data_years.keys())\n",
    "    if year > max_year:\n",
    "        # Calculate the yearly growth rate using the last year's data\n",
    "        last_year_growth = data_years[max_year] - data_years[max_year - 1]\n",
    "        years_difference = year - max_year\n",
    "        days_progress = progress\n",
    "        \n",
    "        # Project into the future using the growth rate\n",
    "        projected_value = data_years[max_year] + (last_year_growth * years_difference) + (last_year_growth * days_progress)\n",
    "        return round(projected_value, 1)\n",
    "        \n",
    "    raise ValueError(f\"Date must be after {min(data_years.keys())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216244.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# usage example\n",
    "#get_gold_above_ground_supply(datetime.now(), data) \n",
    "get_gold_above_ground_supply(datetime(2024, 1, 1), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to get the ETH total supply over time ...? tba via Dune query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etherscan is paid plan only\n",
    "# Coingecko API is free but only estimate\n",
    "# DUNE???\n",
    "# TODO!\n",
    "\n",
    "import requests\n",
    "\n",
    "# Etherscan API key\n",
    "ETHERSCAN_API_KEY = os.environ['ETHERSCAN_API_KEY']\n",
    "\n",
    "# Function to get ETH total supply at a block\n",
    "def get_eth_supply_at_block(block_number):\n",
    "    url = f'https://api.etherscan.io/api?module=proxy&action=eth_getBlockByNumber&tag={hex(block_number)}&boolean=true&apikey={ETHERSCAN_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'result' in data:\n",
    "        block_reward = int(data['result']['blockReward'], 16)  # Block reward in Wei\n",
    "        return block_reward / (10 ** 18)  # Convert Wei to ETH\n",
    "    else:\n",
    "        print(f\"Error fetching ETH supply at block {block_number}: {data}\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Beaconchain Staked Amount Per Validator Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in octant_validators.txt\n",
    "with open('octant_validators.txt', 'r') as file:\n",
    "    octant_validators = file.read().splitlines()\n",
    "\n",
    "# turn str to number\n",
    "octant_validators = [int(i) for i in octant_validators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validators: 3136\n",
      "Total Balance: 100417.20743824 ETH\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_validator_balance(validator_ids, slot='head'):\n",
    "    url = f'https://ethereum-beacon-api.publicnode.com/eth/v1/beacon/states/{slot}/validators'\n",
    "    total_balance = 0\n",
    "    all_data = []\n",
    "\n",
    "    for i in range(0, len(validator_ids), 100):\n",
    "        batch = validator_ids[i:i+100]\n",
    "        params = {'id': ','.join(map(str, batch))}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Extract and sum up balances\n",
    "            balances = [int(validator['balance']) for validator in data['data']]\n",
    "            total_balance += sum(balances)\n",
    "            all_data.extend(data['data'])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching validator rewards: {e}\")\n",
    "            return None, 0\n",
    "\n",
    "    return all_data, total_balance\n",
    "\n",
    "# Example usage\n",
    "result, total_balance = get_validator_balance(octant_validators)\n",
    "print(\"Validators:\", len(result))\n",
    "print(\"Total Balance:\", total_balance/10**9, \"ETH\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POS Rewards & Slashing per slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'execution_optimistic': False, 'finalized': True, 'data': {'proposer_index': '210278', 'total': '46021514', 'attestations': '44398130', 'sync_aggregate': '1623384', 'proposer_slashings': '0', 'attester_slashings': '0'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "rpc_endpoint = \"https://lb.drpc.org/rest/eth-beacon-chain\"\n",
    "rpc_endpoint2 = \"https://ethereum-beacon-api.publicnode.com\"\n",
    "\n",
    "def get_beacon_rewards(slot=\"head\"):\n",
    "    url = f'{rpc_endpoint3}/eth/v1/beacon/rewards/blocks/{slot}'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching rewards for slot {slot}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "slot = 10476864\n",
    "rewards = get_beacon_rewards(slot)\n",
    "print(rewards)\n",
    "\n",
    "# problem: old slots take a lot of time to fetch...? 60s+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()  # Initialize df_all as an empty DataFrame\n",
    "\n",
    "for i in range(0, 10):\n",
    "    slot = 10476864 + i\n",
    "    rewards = get_beacon_rewards(slot)\n",
    "    rewards['data']['slot'] = slot\n",
    "    df = pd.DataFrame([rewards['data']])\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "df_all.to_csv('beacon_rewards.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
